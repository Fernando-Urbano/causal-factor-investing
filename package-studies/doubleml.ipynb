{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple DML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: 1.8844; SE: 0.0643\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from doubleml import DoubleMLData, DoubleMLPLR\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "N_SAMPLES = 1000\n",
    "N_FEATURES = 10\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "X = np.random.normal(0, 1, size=(N_SAMPLES, N_FEATURES))\n",
    "treatment_prob = 1 / (1 + np.exp(-0.5 * X[:, 0]))\n",
    "t = np.random.binomial(1, treatment_prob, size=N_SAMPLES)\n",
    "y = 2 * t + 0.3 * X[:, 1] - 0.5 * X[:, 2] + np.random.normal(0, 1, size=N_SAMPLES)\n",
    "\n",
    "data = DoubleMLData.from_arrays(X, y, t)\n",
    "\n",
    "# Outcome model m(X)\n",
    "model_m_x = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "# Propensity score model g(X)\n",
    "model_g_x = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "dml_plr = DoubleMLPLR(data, model_m_x, model_g_x, n_folds=5)\n",
    "\n",
    "dml_plr.fit()\n",
    "\n",
    "ate = dml_plr._coef[0]\n",
    "se = dml_plr._se[0]\n",
    "print(f\"ATE: {ate:.4f}; SE: {se:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple DML with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: 1.8962; SE: 0.0661\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>1.896212</td>\n",
       "      <td>0.06611</td>\n",
       "      <td>28.682832</td>\n",
       "      <td>6.247396e-181</td>\n",
       "      <td>1.76664</td>\n",
       "      <td>2.025785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coef  std err          t          P>|t|    2.5 %    97.5 %\n",
       "d  1.896212  0.06611  28.682832  6.247396e-181  1.76664  2.025785"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_m = {'max_depth': [3, 5, 7]}\n",
    "param_grid_g = {'max_depth': [3, 5, 7]}\n",
    "\n",
    "data = DoubleMLData.from_arrays(X, y, t)\n",
    "\n",
    "base_learner_m = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "ml_m = GridSearchCV(base_learner_m, param_grid_m, cv=3)\n",
    "\n",
    "base_learner_g = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "ml_g = GridSearchCV(base_learner_g, param_grid_g, cv=3)\n",
    "\n",
    "dml_plr = DoubleMLPLR(data, ml_m, ml_g, n_folds=5)\n",
    "dml_plr.fit()\n",
    "\n",
    "ate = dml_plr._coef[0]\n",
    "se = dml_plr._se[0]\n",
    "print(f\"ATE: {ate:.4f}; SE: {se:.4f}\")\n",
    "dml_plr.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Different Covariates to Predict Treatment and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>1.937841</td>\n",
       "      <td>0.07312</td>\n",
       "      <td>26.502299</td>\n",
       "      <td>9.118737e-155</td>\n",
       "      <td>1.794529</td>\n",
       "      <td>2.081153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coef  std err          t          P>|t|     2.5 %    97.5 %\n",
       "d  1.937841  0.07312  26.502299  9.118737e-155  1.794529  2.081153"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "# Covariates\n",
    "X1 = np.random.normal(size=n_samples)\n",
    "X2 = np.random.normal(size=n_samples)\n",
    "X3 = np.random.normal(size=n_samples)\n",
    "X4 = np.random.normal(size=n_samples)\n",
    "X5 = np.random.normal(size=n_samples)\n",
    "X6 = np.random.normal(size=n_samples)\n",
    "\n",
    "# DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'X1': X1,\n",
    "    'X2': X2,\n",
    "    'X3': X3,\n",
    "    'X4': X4,\n",
    "    'X5': X5,\n",
    "    'X6': X6,\n",
    "})\n",
    "\n",
    "covariates_g = [0, 1, 2]\n",
    "covariates_m = [1, 3, 5]\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "df['treatment'] = np.random.binomial(1, expit(0.5 * df['X1'] - 0.3 * df['X2'] + 0.2 * df['X3']))\n",
    "df['outcome'] = 2 * df['treatment'] + 0.5 * df['X4'] - 0.7 * df['X5'] + 0.3 * df['X6'] + np.random.normal(size=n_samples)\n",
    "\n",
    "# For g(X)\n",
    "preprocessor_g = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('select_columns', 'passthrough', covariates_g)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline_g = Pipeline([\n",
    "    ('preprocessor', preprocessor_g),\n",
    "    ('model', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42))\n",
    "])\n",
    "\n",
    "# For m(X)\n",
    "preprocessor_m = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('select_columns', 'passthrough', covariates_m)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline_m = Pipeline([\n",
    "    ('preprocessor', preprocessor_m),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42))\n",
    "])\n",
    "\n",
    "dml_plr = DoubleMLPLR(data, pipeline_m, pipeline_g, n_folds=5)\n",
    "dml_plr.fit()\n",
    "\n",
    "dml_plr.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do GridSearchCV with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <td>2.009888</td>\n",
       "      <td>0.079271</td>\n",
       "      <td>25.354521</td>\n",
       "      <td>8.011809e-142</td>\n",
       "      <td>1.854519</td>\n",
       "      <td>2.165257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               coef   std err          t          P>|t|     2.5 %    97.5 %\n",
       "treatment  2.009888  0.079271  25.354521  8.011809e-142  1.854519  2.165257"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Preprocessing step: select relevant columns\n",
    "preprocessor_m = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('select_columns', 'passthrough', [1, 2, 3])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline_m = Pipeline([\n",
    "    ('preprocessor', preprocessor_m),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_m = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_m = GridSearchCV(\n",
    "    estimator=pipeline_m,\n",
    "    param_grid=param_grid_m,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "from doubleml import DoubleMLData, DoubleMLPLR\n",
    "\n",
    "data = DoubleMLData(df, y_col='outcome', d_cols='treatment')\n",
    "\n",
    "pipeline_g = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer(\n",
    "        transformers=[('select_columns', 'passthrough', [1, 2, 3])],\n",
    "        remainder='drop'\n",
    "    )),\n",
    "    ('model', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_g = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_g = GridSearchCV(\n",
    "    estimator=pipeline_g,\n",
    "    param_grid=param_grid_g,\n",
    "    cv=5,\n",
    "    scoring='balanced_accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "dml_plr = DoubleMLPLR(data, grid_search_m, grid_search_g, n_folds=5)\n",
    "\n",
    "dml_plr.fit()\n",
    "dml_plr.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Preprocessing step: select relevant columns and create polynomial features\n",
    "preprocessor_lasso = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('select_columns', 'passthrough', [1, 2, 3])  # Columns to use\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_lasso),\n",
    "    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),  # Add polynomial features\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('lasso', LassoCV(cv=5, random_state=42))  # Cross-validated LASSO\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Preprocessing step: select relevant columns\n",
    "preprocessor_dnn = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('select_columns', 'passthrough', [1, 2, 3])  # Columns to use\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "dnn_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_dnn),\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('mlp', MLPRegressor(max_iter=1000, random_state=42))  # Neural network\n",
    "])\n",
    "\n",
    "# Define the parameter grid for the DNN\n",
    "param_grid_dnn = {\n",
    "    'mlp__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],  # Architectures\n",
    "    'mlp__alpha': [0.001, 0.01, 0.1, 1],  # Ridge regularization\n",
    "    'mlp__activation': ['relu', 'tanh'],  # Activation functions\n",
    "    'mlp__learning_rate': ['constant', 'adaptive']  # Learning rate strategies\n",
    "}\n",
    "\n",
    "# Wrap the pipeline in GridSearchCV\n",
    "grid_search_dnn = GridSearchCV(\n",
    "    estimator=dnn_pipeline,\n",
    "    param_grid=param_grid_dnn,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrumental Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       coef   std err          t         P>|t|     2.5 %    97.5 %\n",
      "D  1.990362  0.114688  17.354629  1.819723e-67  1.765579  2.215146\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from doubleml import DoubleMLPLIV, DoubleMLData\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_column_indices(dataframe: pd.DataFrame, column_names: list) -> list[int]:\n",
    "    \"\"\"\n",
    "    Get the column indices of specified column names in a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): Theb DataFrame containing the columns.\n",
    "    column_names (list): A list of column names for which to retrieve indices.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of column indices corresponding to the specified column names.\n",
    "    \"\"\"\n",
    "    # Ensure all column names are present in the DataFrame\n",
    "    missing_columns = [col for col in column_names if col not in dataframe.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"The following columns are not in the DataFrame: {missing_columns}\")\n",
    "    \n",
    "    return [dataframe.columns.get_loc(col) for col in column_names]\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_features = 5\n",
    "\n",
    "X = np.random.normal(size=(n_samples, n_features))\n",
    "Z = np.random.binomial(1, 0.5, size=n_samples)  # Binary instrument\n",
    "D = 0.5 * Z + 0.3 * X[:, 0] + np.random.normal(0, 1, size=n_samples)\n",
    "Y = 2.0 * D + 0.5 * X[:, 1] + np.random.normal(0, 1, size=n_samples)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X, columns=[f'X{i+1}' for i in range(n_features)])\n",
    "df['Z'] = Z\n",
    "df['D'] = D\n",
    "df['Y'] = Y\n",
    "\n",
    "# Specify DoubleML data\n",
    "data = DoubleMLData(df, y_col='Y', d_cols='D', z_cols='Z')\n",
    "\n",
    "x_indices = get_column_indices(df, x_columns)\n",
    "\n",
    "# Define a pipeline for outcome model m(X)\n",
    "preprocessor_m = ColumnTransformer(\n",
    "    transformers=[('scaler', StandardScaler(), x_indices)],  # Use indices\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline_m = Pipeline([\n",
    "    ('preprocessor', preprocessor_m),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_m = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_m = GridSearchCV(\n",
    "    estimator=pipeline_m,\n",
    "    param_grid=param_grid_m,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Define a pipeline for treatment model l(Z, X)\n",
    "preprocessor_l = ColumnTransformer(\n",
    "    transformers=[('scaler', StandardScaler(), x_indices)],  # Indices for X and Z\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline_l = Pipeline([\n",
    "    ('preprocessor', preprocessor_l),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_l = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_l = GridSearchCV(\n",
    "    estimator=pipeline_l,\n",
    "    param_grid=param_grid_l,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Define a pipeline for instrument model r(Z, X)\n",
    "pipeline_r = Pipeline([\n",
    "    ('preprocessor', preprocessor_l),  # Similar preprocessor as l(Z, X)\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_r = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_r = GridSearchCV(\n",
    "    estimator=pipeline_r,\n",
    "    param_grid=param_grid_r,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Initialize DoubleMLPLIV object\n",
    "dml_pliv = DoubleMLPLIV(\n",
    "    obj_dml_data=data,\n",
    "    ml_l=grid_search_l,  # Treatment model\n",
    "    ml_m=grid_search_m,  # Outcome model\n",
    "    ml_r=grid_search_r   # Instrument model\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "dml_pliv.fit()\n",
    "\n",
    "# Print summary\n",
    "print(dml_pliv.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frontdoor Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       coef   std err          t          P>|t|     2.5 %   97.5 %\n",
      "D  1.260351  0.046837  26.909214  1.713417e-159  1.168552  1.35215\n",
      "       coef   std err          t          P>|t|     2.5 %   97.5 %\n",
      "D  1.246652  0.052709  23.651739  1.132662e-123  1.143345  1.34996\n",
      "       coef   std err          t          P>|t|     2.5 %    97.5 %\n",
      "D  1.295172  0.048491  26.709593  3.641799e-157  1.200131  1.390212\n",
      "       coef   std err        t          P>|t|     2.5 %    97.5 %\n",
      "D  1.227967  0.039574  31.0295  2.157074e-211  1.150403  1.305531\n",
      "       coef  std err          t          P>|t|     2.5 %    97.5 %\n",
      "D  1.347179  0.04646  28.996437  7.296705e-185  1.256119  1.438239\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from doubleml import DoubleMLPLIV, DoubleMLData\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Generate synthetic data for front-door adjustment\n",
    "np.random.seed(42)\n",
    "for _ in range(5):\n",
    "    n_samples = 100\n",
    "    X = np.random.normal(size=(n_samples, 3))  # Covariates\n",
    "    D = np.random.binomial(1, 0.5, size=n_samples)  # Treatment\n",
    "    M = 0.8 * D + 0.2 * X[:, 0] + np.random.normal(0, 0.1, size=n_samples)  # Mediator\n",
    "    Y = 1.5 * M + 0.2 * X[:, 0] + np.random.normal(0, 0.1, size=n_samples)  # Outcome\n",
    "\n",
    "    df = pd.DataFrame(X, columns=['X1', 'X2', 'X3'])\n",
    "    df['D'] = D\n",
    "    df['M'] = M\n",
    "    df['Y'] = Y\n",
    "\n",
    "    # DoubleML data\n",
    "    data = DoubleMLData(df, y_col='Y', d_cols='D', z_cols='M')\n",
    "\n",
    "    # Define learners\n",
    "    learner = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "    # Models for nuisance functions\n",
    "    ml_l = GridSearchCV(Pipeline([('model', learner)]), param_grid={}, cv=3)\n",
    "    ml_m = GridSearchCV(Pipeline([('model', learner)]), param_grid={}, cv=3)\n",
    "    ml_r = GridSearchCV(Pipeline([('model', learner)]), param_grid={}, cv=3)\n",
    "\n",
    "    # DoubleMLPLIV object\n",
    "    dml_pliv = DoubleMLPLIV(data, ml_l=ml_l, ml_m=ml_m, ml_r=ml_r)\n",
    "\n",
    "    # Fit the model\n",
    "    dml_pliv.fit()\n",
    "\n",
    "    # Print the summary\n",
    "    print(dml_pliv.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Between Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.201532</td>\n",
       "      <td>0.043825</td>\n",
       "      <td>0.297731</td>\n",
       "      <td>-2.514653</td>\n",
       "      <td>0.102072</td>\n",
       "      <td>0.087034</td>\n",
       "      <td>-0.401188</td>\n",
       "      <td>1.952198</td>\n",
       "      <td>-0.381415</td>\n",
       "      <td>0.478923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043825</td>\n",
       "      <td>0.767785</td>\n",
       "      <td>-0.113593</td>\n",
       "      <td>0.151767</td>\n",
       "      <td>0.032833</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>-0.003126</td>\n",
       "      <td>-0.034657</td>\n",
       "      <td>0.019952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297731</td>\n",
       "      <td>-0.113593</td>\n",
       "      <td>7.877645</td>\n",
       "      <td>-0.183830</td>\n",
       "      <td>0.063273</td>\n",
       "      <td>0.017774</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0.289051</td>\n",
       "      <td>-0.414976</td>\n",
       "      <td>-0.382765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.514653</td>\n",
       "      <td>0.151767</td>\n",
       "      <td>-0.183830</td>\n",
       "      <td>9.472169</td>\n",
       "      <td>0.163902</td>\n",
       "      <td>-0.167743</td>\n",
       "      <td>0.697450</td>\n",
       "      <td>-1.314637</td>\n",
       "      <td>0.416422</td>\n",
       "      <td>-0.271861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.102072</td>\n",
       "      <td>0.032833</td>\n",
       "      <td>0.063273</td>\n",
       "      <td>0.163902</td>\n",
       "      <td>1.429548</td>\n",
       "      <td>0.019877</td>\n",
       "      <td>-0.024886</td>\n",
       "      <td>0.170254</td>\n",
       "      <td>0.078595</td>\n",
       "      <td>0.043645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.087034</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>0.017774</td>\n",
       "      <td>-0.167743</td>\n",
       "      <td>0.019877</td>\n",
       "      <td>1.365512</td>\n",
       "      <td>-0.100100</td>\n",
       "      <td>0.067493</td>\n",
       "      <td>-0.032747</td>\n",
       "      <td>0.005909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.401188</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0.697450</td>\n",
       "      <td>-0.024886</td>\n",
       "      <td>-0.100100</td>\n",
       "      <td>2.303199</td>\n",
       "      <td>0.105149</td>\n",
       "      <td>0.192926</td>\n",
       "      <td>-0.021746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.952198</td>\n",
       "      <td>-0.003126</td>\n",
       "      <td>0.289051</td>\n",
       "      <td>-1.314637</td>\n",
       "      <td>0.170254</td>\n",
       "      <td>0.067493</td>\n",
       "      <td>0.105149</td>\n",
       "      <td>6.960944</td>\n",
       "      <td>-0.137170</td>\n",
       "      <td>0.304518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.381415</td>\n",
       "      <td>-0.034657</td>\n",
       "      <td>-0.414976</td>\n",
       "      <td>0.416422</td>\n",
       "      <td>0.078595</td>\n",
       "      <td>-0.032747</td>\n",
       "      <td>0.192926</td>\n",
       "      <td>-0.137170</td>\n",
       "      <td>0.789918</td>\n",
       "      <td>-0.054666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.478923</td>\n",
       "      <td>0.019952</td>\n",
       "      <td>-0.382765</td>\n",
       "      <td>-0.271861</td>\n",
       "      <td>0.043645</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>-0.021746</td>\n",
       "      <td>0.304518</td>\n",
       "      <td>-0.054666</td>\n",
       "      <td>2.181609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  6.201532  0.043825  0.297731 -2.514653  0.102072  0.087034 -0.401188   \n",
       "1  0.043825  0.767785 -0.113593  0.151767  0.032833 -0.000447  0.003809   \n",
       "2  0.297731 -0.113593  7.877645 -0.183830  0.063273  0.017774 -0.416667   \n",
       "3 -2.514653  0.151767 -0.183830  9.472169  0.163902 -0.167743  0.697450   \n",
       "4  0.102072  0.032833  0.063273  0.163902  1.429548  0.019877 -0.024886   \n",
       "5  0.087034 -0.000447  0.017774 -0.167743  0.019877  1.365512 -0.100100   \n",
       "6 -0.401188  0.003809 -0.416667  0.697450 -0.024886 -0.100100  2.303199   \n",
       "7  1.952198 -0.003126  0.289051 -1.314637  0.170254  0.067493  0.105149   \n",
       "8 -0.381415 -0.034657 -0.414976  0.416422  0.078595 -0.032747  0.192926   \n",
       "9  0.478923  0.019952 -0.382765 -0.271861  0.043645  0.005909 -0.021746   \n",
       "\n",
       "          7         8         9  \n",
       "0  1.952198 -0.381415  0.478923  \n",
       "1 -0.003126 -0.034657  0.019952  \n",
       "2  0.289051 -0.414976 -0.382765  \n",
       "3 -1.314637  0.416422 -0.271861  \n",
       "4  0.170254  0.078595  0.043645  \n",
       "5  0.067493 -0.032747  0.005909  \n",
       "6  0.105149  0.192926 -0.021746  \n",
       "7  6.960944 -0.137170  0.304518  \n",
       "8 -0.137170  0.789918 -0.054666  \n",
       "9  0.304518 -0.054666  2.181609  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_sparse_spd_matrix, make_spd_matrix\n",
    "\n",
    "d = 10\n",
    "avg_corr_covariates = .1\n",
    "\n",
    "cov_matrix = make_sparse_spd_matrix(d, alpha=0) * make_spd_matrix(d)\n",
    "pd.DataFrame(cov_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
